{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_14164\\945315476.py:9: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/combined.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588647, 51)\n",
      "This work was done by Philip!\n"
     ]
    }
   ],
   "source": [
    "# import required libraries and load data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data/combined.csv')\n",
    "\n",
    "# How big is this dataset?\n",
    "print(df.shape)\n",
    "print('This work was done by Philip!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice the errorr that columns 29, 34, 35 and 37 have mixed data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data description and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN_YEARMONTH         int64\n",
      "BEGIN_DAY               int64\n",
      "BEGIN_TIME              int64\n",
      "END_YEARMONTH           int64\n",
      "END_DAY                 int64\n",
      "END_TIME                int64\n",
      "EPISODE_ID              int64\n",
      "EVENT_ID                int64\n",
      "STATE                  object\n",
      "STATE_FIPS            float64\n",
      "YEAR                    int64\n",
      "MONTH_NAME             object\n",
      "EVENT_TYPE             object\n",
      "CZ_TYPE                object\n",
      "CZ_FIPS                 int64\n",
      "CZ_NAME                object\n",
      "WFO                    object\n",
      "BEGIN_DATE_TIME        object\n",
      "CZ_TIMEZONE            object\n",
      "END_DATE_TIME          object\n",
      "INJURIES_DIRECT         int64\n",
      "INJURIES_INDIRECT       int64\n",
      "DEATHS_DIRECT           int64\n",
      "DEATHS_INDIRECT         int64\n",
      "DAMAGE_PROPERTY        object\n",
      "DAMAGE_CROPS           object\n",
      "SOURCE                 object\n",
      "MAGNITUDE             float64\n",
      "MAGNITUDE_TYPE         object\n",
      "FLOOD_CAUSE            object\n",
      "CATEGORY              float64\n",
      "TOR_F_SCALE            object\n",
      "TOR_LENGTH            float64\n",
      "TOR_WIDTH             float64\n",
      "TOR_OTHER_WFO          object\n",
      "TOR_OTHER_CZ_STATE     object\n",
      "TOR_OTHER_CZ_FIPS     float64\n",
      "TOR_OTHER_CZ_NAME      object\n",
      "BEGIN_RANGE           float64\n",
      "BEGIN_AZIMUTH          object\n",
      "BEGIN_LOCATION         object\n",
      "END_RANGE             float64\n",
      "END_AZIMUTH            object\n",
      "END_LOCATION           object\n",
      "BEGIN_LAT             float64\n",
      "BEGIN_LON             float64\n",
      "END_LAT               float64\n",
      "END_LON               float64\n",
      "EPISODE_NARRATIVE      object\n",
      "EVENT_NARRATIVE        object\n",
      "DATA_SOURCE            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1588647 entries, 0 to 1588646\n",
      "Data columns (total 51 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   BEGIN_YEARMONTH     1588647 non-null  int64  \n",
      " 1   BEGIN_DAY           1588647 non-null  int64  \n",
      " 2   BEGIN_TIME          1588647 non-null  int64  \n",
      " 3   END_YEARMONTH       1588647 non-null  int64  \n",
      " 4   END_DAY             1588647 non-null  int64  \n",
      " 5   END_TIME            1588647 non-null  int64  \n",
      " 6   EPISODE_ID          1588647 non-null  int64  \n",
      " 7   EVENT_ID            1588647 non-null  int64  \n",
      " 8   STATE               1588646 non-null  object \n",
      " 9   STATE_FIPS          1588646 non-null  float64\n",
      " 10  YEAR                1588647 non-null  int64  \n",
      " 11  MONTH_NAME          1588647 non-null  object \n",
      " 12  EVENT_TYPE          1588647 non-null  object \n",
      " 13  CZ_TYPE             1588647 non-null  object \n",
      " 14  CZ_FIPS             1588647 non-null  int64  \n",
      " 15  CZ_NAME             1588647 non-null  object \n",
      " 16  WFO                 1588647 non-null  object \n",
      " 17  BEGIN_DATE_TIME     1588647 non-null  object \n",
      " 18  CZ_TIMEZONE         1588647 non-null  object \n",
      " 19  END_DATE_TIME       1588647 non-null  object \n",
      " 20  INJURIES_DIRECT     1588647 non-null  int64  \n",
      " 21  INJURIES_INDIRECT   1588647 non-null  int64  \n",
      " 22  DEATHS_DIRECT       1588647 non-null  int64  \n",
      " 23  DEATHS_INDIRECT     1588647 non-null  int64  \n",
      " 24  DAMAGE_PROPERTY     1064972 non-null  object \n",
      " 25  DAMAGE_CROPS        970592 non-null   object \n",
      " 26  SOURCE              1565533 non-null  object \n",
      " 27  MAGNITUDE           828624 non-null   float64\n",
      " 28  MAGNITUDE_TYPE      502454 non-null   object \n",
      " 29  FLOOD_CAUSE         114862 non-null   object \n",
      " 30  CATEGORY            484 non-null      float64\n",
      " 31  TOR_F_SCALE         37992 non-null    object \n",
      " 32  TOR_LENGTH          37992 non-null    float64\n",
      " 33  TOR_WIDTH           37992 non-null    float64\n",
      " 34  TOR_OTHER_WFO       3346 non-null     object \n",
      " 35  TOR_OTHER_CZ_STATE  3346 non-null     object \n",
      " 36  TOR_OTHER_CZ_FIPS   3346 non-null     float64\n",
      " 37  TOR_OTHER_CZ_NAME   3346 non-null     object \n",
      " 38  BEGIN_RANGE         808017 non-null   float64\n",
      " 39  BEGIN_AZIMUTH       808017 non-null   object \n",
      " 40  BEGIN_LOCATION      994811 non-null   object \n",
      " 41  END_RANGE           808057 non-null   float64\n",
      " 42  END_AZIMUTH         808057 non-null   object \n",
      " 43  END_LOCATION        994811 non-null   object \n",
      " 44  BEGIN_LAT           942205 non-null   float64\n",
      " 45  BEGIN_LON           942198 non-null   float64\n",
      " 46  END_LAT             942205 non-null   float64\n",
      " 47  END_LON             942198 non-null   float64\n",
      " 48  EPISODE_NARRATIVE   1372422 non-null  object \n",
      " 49  EVENT_NARRATIVE     994578 non-null   object \n",
      " 50  DATA_SOURCE         1588647 non-null  object \n",
      "dtypes: float64(12), int64(14), object(25)\n",
      "memory usage: 618.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN_YEARMONTH             0\n",
      "BEGIN_DAY                   0\n",
      "BEGIN_TIME                  0\n",
      "END_YEARMONTH               0\n",
      "END_DAY                     0\n",
      "END_TIME                    0\n",
      "EPISODE_ID                  0\n",
      "EVENT_ID                    0\n",
      "STATE                       1\n",
      "STATE_FIPS                  1\n",
      "YEAR                        0\n",
      "MONTH_NAME                  0\n",
      "EVENT_TYPE                  0\n",
      "CZ_TYPE                     0\n",
      "CZ_FIPS                     0\n",
      "CZ_NAME                     0\n",
      "WFO                         0\n",
      "BEGIN_DATE_TIME             0\n",
      "CZ_TIMEZONE                 0\n",
      "END_DATE_TIME               0\n",
      "INJURIES_DIRECT             0\n",
      "INJURIES_INDIRECT           0\n",
      "DEATHS_DIRECT               0\n",
      "DEATHS_INDIRECT             0\n",
      "DAMAGE_PROPERTY        523675\n",
      "DAMAGE_CROPS           618055\n",
      "SOURCE                  23114\n",
      "MAGNITUDE              760023\n",
      "MAGNITUDE_TYPE        1086193\n",
      "FLOOD_CAUSE           1473785\n",
      "CATEGORY              1588163\n",
      "TOR_F_SCALE           1550655\n",
      "TOR_LENGTH            1550655\n",
      "TOR_WIDTH             1550655\n",
      "TOR_OTHER_WFO         1585301\n",
      "TOR_OTHER_CZ_STATE    1585301\n",
      "TOR_OTHER_CZ_FIPS     1585301\n",
      "TOR_OTHER_CZ_NAME     1585301\n",
      "BEGIN_RANGE            780630\n",
      "BEGIN_AZIMUTH          780630\n",
      "BEGIN_LOCATION         593836\n",
      "END_RANGE              780590\n",
      "END_AZIMUTH            780590\n",
      "END_LOCATION           593836\n",
      "BEGIN_LAT              646442\n",
      "BEGIN_LON              646449\n",
      "END_LAT                646442\n",
      "END_LON                646449\n",
      "EPISODE_NARRATIVE      216225\n",
      "EVENT_NARRATIVE        594069\n",
      "DATA_SOURCE                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many of these columns are not going to be of any value to us here.  We will eliminate the unwanted columns first.  Many of the unwanted columns also have nulls.  We solve two problems by this elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns: 'EVENT_NARRATIVE', 'DATA_SOURCE' and 31 other columns\n",
    "df = df.drop(columns=['EVENT_NARRATIVE', 'DATA_SOURCE', 'EPISODE_NARRATIVE', 'END_LON', 'END_LAT', 'BEGIN_LON', 'BEGIN_LAT', 'END_LOCATION', 'END_AZIMUTH', 'END_RANGE', 'BEGIN_LOCATION', 'BEGIN_AZIMUTH', 'BEGIN_RANGE', 'TOR_OTHER_CZ_NAME', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_WFO', 'TOR_WIDTH', 'TOR_LENGTH', 'TOR_F_SCALE', 'CATEGORY', 'FLOOD_CAUSE', 'MAGNITUDE_TYPE', 'MAGNITUDE', 'SOURCE', 'DAMAGE_CROPS', 'DAMAGE_PROPERTY', 'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME', 'CZ_FIPS', 'CZ_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588647, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN_YEARMONTH      0\n",
      "BEGIN_DAY            0\n",
      "BEGIN_TIME           0\n",
      "END_YEARMONTH        0\n",
      "END_DAY              0\n",
      "END_TIME             0\n",
      "EPISODE_ID           0\n",
      "EVENT_ID             0\n",
      "STATE                1\n",
      "STATE_FIPS           1\n",
      "YEAR                 0\n",
      "MONTH_NAME           0\n",
      "EVENT_TYPE           0\n",
      "CZ_NAME              0\n",
      "INJURIES_DIRECT      0\n",
      "INJURIES_INDIRECT    0\n",
      "DEATHS_DIRECT        0\n",
      "DEATHS_INDIRECT      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more manageable dataset.  Only two columns have a null.  Probably the same row.  Let's look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
      "264567           200308         27        1220         200308       27   \n",
      "\n",
      "        END_TIME  EPISODE_ID  EVENT_ID STATE  STATE_FIPS  YEAR MONTH_NAME  \\\n",
      "264567      1224     1146436   5338997   NaN         NaN  2003     August   \n",
      "\n",
      "        EVENT_TYPE              CZ_NAME  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
      "264567  Waterspout  GUAM COASTAL WATERS                0                  0   \n",
      "\n",
      "        DEATHS_DIRECT  DEATHS_INDIRECT  \n",
      "264567              0                0  \n"
     ]
    }
   ],
   "source": [
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Guam isn't really a state.  Are there other instances for Guam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, END_TIME, EPISODE_ID, EVENT_ID, STATE, STATE_FIPS, YEAR, MONTH_NAME, EVENT_TYPE, CZ_NAME, INJURIES_DIRECT, INJURIES_INDIRECT, DEATHS_DIRECT, DEATHS_INDIRECT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and you are searching in a column named 'column_name'\n",
    "guam_rows = df[df['STATE'].str.contains('Guam', na=False)]\n",
    "print(guam_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently Guam doesn't have any other data in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
      "264567           200308         27        1220         200308       27   \n",
      "\n",
      "        END_TIME  EPISODE_ID  EVENT_ID STATE  STATE_FIPS  YEAR MONTH_NAME  \\\n",
      "264567      1224     1146436   5338997  Guam         NaN  2003     August   \n",
      "\n",
      "        EVENT_TYPE              CZ_NAME  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
      "264567  Waterspout  GUAM COASTAL WATERS                0                  0   \n",
      "\n",
      "        DEATHS_DIRECT  DEATHS_INDIRECT  \n",
      "264567              0                0  \n"
     ]
    }
   ],
   "source": [
    "df['STATE'] = df['STATE'].fillna('Guam')\n",
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that this dataset is almost ready.  There are a few columns to get rid of.  State fips and CZ name.  \n",
    "There are several different types of time here.  Not sure that they are all useful, keeping them for now.\n",
    "I also want to combine the injuries and death columns into a single deaths and injuries column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1588647 entries, 0 to 1588646\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   BEGIN_YEARMONTH        1588647 non-null  int64 \n",
      " 1   BEGIN_DAY              1588647 non-null  int64 \n",
      " 2   BEGIN_TIME             1588647 non-null  int64 \n",
      " 3   END_YEARMONTH          1588647 non-null  int64 \n",
      " 4   END_DAY                1588647 non-null  int64 \n",
      " 5   END_TIME               1588647 non-null  int64 \n",
      " 6   EPISODE_ID             1588647 non-null  int64 \n",
      " 7   EVENT_ID               1588647 non-null  int64 \n",
      " 8   STATE                  1588647 non-null  object\n",
      " 9   YEAR                   1588647 non-null  int64 \n",
      " 10  MONTH_NAME             1588647 non-null  object\n",
      " 11  EVENT_TYPE             1588647 non-null  object\n",
      " 12  INJURIES_DIRECT        1588647 non-null  int64 \n",
      " 13  INJURIES_INDIRECT      1588647 non-null  int64 \n",
      " 14  DEATHS_DIRECT          1588647 non-null  int64 \n",
      " 15  DEATHS_INDIRECT        1588647 non-null  int64 \n",
      " 16  total_injuries_deaths  1588647 non-null  int64 \n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 206.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['CZ_NAME', 'STATE_FIPS'])\n",
    "df['total_injuries_deaths'] = df[['INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT']].sum(axis=1)\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALABAMA', 'ALASKA', 'AMERICAN SAMOA', 'ARIZONA', 'ARKANSAS', 'ATLANTIC NORTH', 'ATLANTIC SOUTH', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA', 'E PACIFIC', 'FLORIDA', 'GEORGIA', 'GUAM', 'GUAM WATERS', 'GULF OF ALASKA', 'GULF OF MEXICO', 'Guam', 'HAWAII', 'HAWAII WATERS', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY', 'LAKE ERIE', 'LAKE HURON', 'LAKE MICHIGAN', 'LAKE ONTARIO', 'LAKE ST CLAIR', 'LAKE SUPERIOR', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'ST LAWRENCE R', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGIN ISLANDS', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING']\n"
     ]
    }
   ],
   "source": [
    "unique_states = df['STATE'].unique()\n",
    "sorted_unique_states = sorted(unique_states)\n",
    "print(sorted_unique_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_to_remove = [\n",
    "    'AMERICAN SAMOA', 'ALASKA', 'ATLANTIC NORTH', 'ATLANTIC SOUTH', 'E PACIFIC', 'GUAM', 'Guam', \n",
    "    'GUAM WATERS', 'GULF OF ALASKA', 'GULF OF MEXICO', 'HAWAII', 'HAWAII WATERS', \n",
    "    'LAKE ERIE', 'LAKE HURON', 'LAKE MICHIGAN', 'LAKE ONTARIO', 'LAKE SUPERIOR', \n",
    "    'LAKE ST CLAIR', 'PUERTO RICO', 'ST LAWRENCE R', 'ST. LAWRENCE RIVER', 'VIRGIN ISLANDS',\n",
    "]\n",
    "\n",
    "df = df[~df['STATE'].isin(states_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALABAMA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA', 'FLORIDA', 'GEORGIA', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING']\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "unique_states = df['STATE'].unique()\n",
    "sorted_unique_states = sorted(unique_states)\n",
    "print(sorted_unique_states)\n",
    "\n",
    "unique_state_count = df['STATE'].nunique()\n",
    "print(unique_state_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thunderstorm Wind' 'Drought' 'Ice Storm' 'Hail' 'Winter Weather' 'Heat'\n",
      " 'Heavy Snow' 'Winter Storm' 'Flash Flood' 'Flood' 'Tropical Storm'\n",
      " 'Lightning' 'High Wind' 'Heavy Rain' 'Strong Wind' 'Tornado'\n",
      " 'Cold/Wind Chill' 'Hurricane (Typhoon)' 'Lake-Effect Snow' 'Sleet'\n",
      " 'Dense Fog' 'Funnel Cloud' 'Blizzard' 'Wildfire' 'Avalanche' 'Waterspout'\n",
      " 'High Surf' 'Storm Surge/Tide' 'Rip Current' 'Seiche' 'Coastal Flood'\n",
      " 'Dust Storm' 'Frost/Freeze' 'Dust Devil' 'Debris Flow' 'Freezing Fog'\n",
      " 'Marine High Wind' 'Extreme Cold/Wind Chill' 'Excessive Heat'\n",
      " 'Northern Lights' 'Volcanic Ash' 'Dense Smoke' 'Tsunami'\n",
      " 'Lakeshore Flood' 'Astronomical Low Tide' 'Tropical Depression'\n",
      " 'Sneakerwave' 'Hurricane']\n"
     ]
    }
   ],
   "source": [
    "unique_event_types = df['EVENT_TYPE'].unique()\n",
    "print(unique_event_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thunderstorm Wind' 'Hail' 'Lightning' 'High Wind' 'Strong Wind'\n",
      " 'Tornado']\n"
     ]
    }
   ],
   "source": [
    "event_types_to_keep = ['Thunderstorm Wind', 'Hail', 'Lightning', 'High Wind', 'Strong Wind', 'Tornado']\n",
    "\n",
    "df = df[df['EVENT_TYPE'].isin(event_types_to_keep)]\n",
    "\n",
    "unique_event_types = df['EVENT_TYPE'].unique()\n",
    "print(unique_event_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the lower 48 states and DC, no nulls, and Thunderstorm related events.  I think that we are ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Start the EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 865841 entries, 0 to 1588646\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   BEGIN_YEARMONTH        865841 non-null  int64 \n",
      " 1   BEGIN_DAY              865841 non-null  int64 \n",
      " 2   BEGIN_TIME             865841 non-null  int64 \n",
      " 3   END_YEARMONTH          865841 non-null  int64 \n",
      " 4   END_DAY                865841 non-null  int64 \n",
      " 5   END_TIME               865841 non-null  int64 \n",
      " 6   EPISODE_ID             865841 non-null  int64 \n",
      " 7   EVENT_ID               865841 non-null  int64 \n",
      " 8   STATE                  865841 non-null  object\n",
      " 9   YEAR                   865841 non-null  int64 \n",
      " 10  MONTH_NAME             865841 non-null  object\n",
      " 11  EVENT_TYPE             865841 non-null  object\n",
      " 12  INJURIES_DIRECT        865841 non-null  int64 \n",
      " 13  INJURIES_INDIRECT      865841 non-null  int64 \n",
      " 14  DEATHS_DIRECT          865841 non-null  int64 \n",
      " 15  DEATHS_INDIRECT        865841 non-null  int64 \n",
      " 16  total_injuries_deaths  865841 non-null  int64 \n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 118.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       BEGIN_YEARMONTH      BEGIN_DAY     BEGIN_TIME  END_YEARMONTH  \\\n",
      "count    865841.000000  865841.000000  865841.000000  865841.000000   \n",
      "mean     201111.129620      15.680162    1500.052070  201111.129620   \n",
      "std         759.937669       8.784279     540.061824     759.937669   \n",
      "min      199801.000000       1.000000       0.000000  199801.000000   \n",
      "25%      200505.000000       8.000000    1315.000000  200505.000000   \n",
      "50%      201105.000000      15.000000    1620.000000  201105.000000   \n",
      "75%      201804.000000      23.000000    1845.000000  201804.000000   \n",
      "max      202406.000000      31.000000    2359.000000  202406.000000   \n",
      "\n",
      "             END_DAY       END_TIME    EPISODE_ID      EVENT_ID  \\\n",
      "count  865841.000000  865841.000000  8.658410e+05  8.658410e+05   \n",
      "mean       15.701210    1525.256082  4.915259e+05  2.110182e+06   \n",
      "std         8.783655     532.538731  6.272493e+05  2.266323e+06   \n",
      "min         1.000000       0.000000  2.000000e+00  5.000000e+00   \n",
      "25%         8.000000    1346.000000  6.731800e+04  4.054080e+05   \n",
      "50%        16.000000    1631.000000  1.425690e+05  8.568860e+05   \n",
      "75%        23.000000    1852.000000  1.121387e+06  5.270517e+06   \n",
      "max        31.000000    2359.000000  2.414827e+06  5.724920e+06   \n",
      "\n",
      "                YEAR  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  \\\n",
      "count  865841.000000    865841.000000      865841.000000  865841.000000   \n",
      "mean     2011.051014         0.046545           0.001855       0.004792   \n",
      "std         7.599938         2.223859           0.341596       0.226336   \n",
      "min      1998.000000         0.000000           0.000000       0.000000   \n",
      "25%      2005.000000         0.000000           0.000000       0.000000   \n",
      "50%      2011.000000         0.000000           0.000000       0.000000   \n",
      "75%      2018.000000         0.000000           0.000000       0.000000   \n",
      "max      2024.000000      1150.000000         275.000000     158.000000   \n",
      "\n",
      "       DEATHS_INDIRECT  total_injuries_deaths  \n",
      "count    865841.000000          865841.000000  \n",
      "mean          0.000447               0.053639  \n",
      "std           0.029330               2.440032  \n",
      "min           0.000000               0.000000  \n",
      "25%           0.000000               0.000000  \n",
      "50%           0.000000               0.000000  \n",
      "75%           0.000000               0.000000  \n",
      "max           8.000000            1311.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN_YEARMONTH          0\n",
      "BEGIN_DAY                0\n",
      "BEGIN_TIME               0\n",
      "END_YEARMONTH            0\n",
      "END_DAY                  0\n",
      "END_TIME                 0\n",
      "EPISODE_ID               0\n",
      "EVENT_ID                 0\n",
      "STATE                    0\n",
      "YEAR                     0\n",
      "MONTH_NAME               0\n",
      "EVENT_TYPE               0\n",
      "INJURIES_DIRECT          0\n",
      "INJURIES_INDIRECT        0\n",
      "DEATHS_DIRECT            0\n",
      "DEATHS_INDIRECT          0\n",
      "total_injuries_deaths    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EVENT_TYPE          STATE  count\n",
      "0         Hail        ALABAMA   5894\n",
      "1         Hail        ARIZONA    927\n",
      "2         Hail       ARKANSAS   8130\n",
      "3         Hail     CALIFORNIA    757\n",
      "4         Hail       COLORADO  11381\n",
      "..         ...            ...    ...\n",
      "289    Tornado       VIRGINIA    571\n",
      "290    Tornado     WASHINGTON     65\n",
      "291    Tornado  WEST VIRGINIA     95\n",
      "292    Tornado      WISCONSIN    782\n",
      "293    Tornado        WYOMING    271\n",
      "\n",
      "[294 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# How many of each event type by state?\n",
    "event_type_by_state = df.groupby(['EVENT_TYPE', 'STATE']).size().reset_index(name='count')\n",
    "print(event_type_by_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
